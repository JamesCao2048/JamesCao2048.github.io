---
layout: post
title:  MindSpore源码阅读系列(二)：编译并调试MindSpore源码
date: 2021-06-23 20:05:00
description: 工欲善其事，必先利其器 -- MindSpore源码阅读准备工作
---

## 前言
往期回顾: [MindSpore源码阅读系列(一)：本地编译API文档并导入Dash](https://jamescao2048.github.io/blog/2021/mindspore1/)

今天我将介绍如何编译并调试MindSpore源码，这对于我们有效地阅读源码非常重要。可编译的环境会让IDE具有**代码跳转、提示**等功能，而调试代码可以让我们通过设置断点的方式捕获程序动态运行的信息，如**局部/全局变量、函数调用栈**等。
这次的内容比较丰富，主要包括：
- [调试Python代码](#test)
  - [阅读MindSpore的Python实现](#测试)
  - [调试MindSpore的Python实现](###调试MindSpore的Python实现)
- [源码编译概览](##调试python代码)
  - [编译流程](###编译流程)
  - [编译脚本(可跳过)](###编译脚本(可跳过))
- [调试C++代码](##调试C++代码)
  - [gdb调试(可跳过)](###gdb调试(可跳过))
  - [VS Code调试(重要)](###VS Code调试(重要))

## 调试Python代码
### 阅读MindSpore的Python实现
由于Python没有编译环节，安装库也只是将库的源码拷贝到指定目录，所以我们可以直接在MindSpore的生产环境调试Python。
使用docker可以方便地安装：
{% highlight bash %}
docker run -it --runtime=nvidia --privileged=true swr.cn-south-1.myhuaweicloud.com/mindspore/mindspore-gpu:1.2.0
{% endhighlight %}
使用IDE阅读Python库的源码非常容易，例如在上述docker中建立文件，写入如下测试代码：
{% highlight python %}
# test_transpose.py
import numpy as np
import mindspore.context as context
import mindspore.ops as ops
import mindspore as ms

context.set_context(mode=context.PYNATIVE_MODE, device_target="GPU")
x = ms.Tensor(np.arange(2 * 3).reshape(2, 3).astype(np.float32))
transpose_op = ops.Transpose()
print(transpose_op(x, (1,0)))
{% endhighlight %}
如果想要查看MindSpore如何实现ops.Transpose的，在VS Code中可以右键后Go to Definition(或选中后按F12):
<div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="{{ site.baseurl }}/assets/img/ms/2/transpose1.png">
</div>
就进入了:
{% highlight python %}
# mindspore/mindspore/ops/operations/array_ops.py
class Transpose(PrimitiveWithInfer):
    @prim_attr_register
    def __init__(self):
        """Initialize Transpose"""
        self.init_prim_io_names(inputs=['x', 'perm'], outputs=['output'])
    def __infer__(self, x, perm):
        ...
{% endhighlight %}
我们知道，Python中形如output = transpose(Tensor(x))这样，将类变量当成函数进行调用，其实是调该类的__call__方法。但是这个Transpose类没有__call__方法啊？秘密在于作为子类是可以继承父类的方法的，它的父类或父类的父类等，实现了__call__方法。
{% highlight python %}
# mindspore/mindspore/ops/primitive.py
from .._c_expression import Primitive_, real_run_op, prim_type

#没有__call__方法
class PrimitiveWithCheck(Primitive):
    ...

#找到__call__方法了
class Primitive(Primitive_):
    def __call__(self, *args):
        should_elim, output = self.check_elim(*args)
        if should_elim:
            return output
        return _run_op(self, self.name, args)
    ...
    @_wrap_func
    def _run_op(obj, op_name, args):
        """Single op execution function supported by ge in PyNative mode."""
        output = real_run_op(obj, op_name, args)
        return output
{% endhighlight %}

总算找到__call__方法了，它是由Transpose的祖父类Primitive实现的。它调用了_run_op方法, 而_run_op实际调用了real_run_op方法执行算子。但是当我们故技重施，想要直接在IDE中跳转到real_run_op方法以及Primitive的父类Primitive_时，却被告知"No Definition found"。

在文件的开头可以发现，Primitive_，real_run_op，prim_type都是从.._c_expression中导入的, '..'意味着c_expression包是在当前文件的上级目录下，即mindspore/mindspore/中。打开mindspore/mindspore/目录，发现有文件_c_expression.cpython-37m-x86_64-linux-gnu.so，**所以_c_expression是个动态链接库，它由C++实现并编译打包，然后python通过cpython的接口导入并使用**。

全文搜索real_run_op发现，mindspore/ccsrc/pipeline/jit/init.cc中，将real_run_op接口绑定为py::object RunOp实现：
{% highlight cpp %}
# mindspore/ccsrc/pipeline/jit/init.cc
(void)m.def("real_run_op", &mindspore::pynative::RunOp, "Run op pynatively.");

# mindspore/ccsrc/pipeline/pynative/pynative_execute.cc
py::object RunOp(const py::args &args) {
  ...
  PynativeExecutorTry(executor->forward_executor()->RunOpS, &ret, op_exec_info);
  return ret;
}
{% endhighlight %}
最终是由PynativeExecutor中的forward_executor的RunOpS方法，根据Op的名称及参数计算结果，并将结果存储在ret中返回。
### 调试MindSpore的Python实现
下面我们想要在primitive.py中的_run_op方法中设置断点，这样以Debug模式运行test_transpose.py时，可以在_run_op中停下来，方便我们查看当时的函数调用栈及变量信息。我们使用VS Code调试，所以需要进行调试配置：在工作目录下的.vscode文件夹中创建launch.json文件，向其中添加：
{% highlight json %}
{
    "configurations": [

        {
            "name": "python",
            "type": "python",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "justMyCode": false
        }
    ]
}
{% endhighlight %}
注意这里的justMyCode设置为false后，在debug模式下，VS Code才会跟踪进入library代码。在_run_op方法中点击设置断点，打开test_transpose.py，按F5进入debug模式，就会停到这里：
<div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="{{ site.baseurl }}/assets/img/ms/2/transpose2.png">
</div>
如图所示，左上角会显示此时的局部变量与全局变量，左下角会显示函数调用栈，正下方的debug console可以输入python表达式与命令解释执行。如果不debug运行，只是通过单纯的源码阅读，就很难轻易地获得这些信息。

这种方式虽然能成功调试MindSpore的Python代码，但是因为real_run_op的真正实现在动态链接库中(对应C++源码mindspore/ccsrc/pipeline/pynative/pynative_execute.cc)，我们无法在debug python时进入pynative_execute.cc中。**那我们怎么调试动态链接库中的方法呢？**

## 源码编译概览
想要调试动态链接库中的代码，我们需要以Debug模式编译MindSpore源码，这样编译器才会把源码与二进制代码的对应关系写入二进制文件(个人理解，可能不准确)。
然后我们在源文件中设置断点后，以debug模式运行二进制文件，就能停在断点位置了。
### 编译流程
首先简单介绍下编译流程。参考[官网源码编译教程](https://www.mindspore.cn/install/),可以看到编译之前需要安装一大堆依赖。所幸官方提供了可以编译的[docker镜像](https://gitee.com/mindspore/mindspore#%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E6%96%B9%E5%BC%8F%E5%AE%89%E8%A3%85)，使用docker拉取devel镜像就无需安装这些依赖了。执行以下命令：
{% highlight bash %}
docker run -it -v /home/fy/disk1/cjm/mindspore:/dev/mindspore --runtime=nvidia --privileged=true swr.cn-south-1.myhuaweicloud.com/mindspore/mindspore-gpu:devel
git clone https://gitee.com/mindspore/mindspore.git
cd mindspore
# 执行下面这条编译命令，生成的whl文件可供python调用API测试，但是不能执行测试用例，也不能进行C++调试。
bash build.sh -e gpu
# 执行下面这条编译命令，可以执行测试用例，进行C++调试，但是不能供python调用API测试
# bash build.sh -e gpu -d -t ut -i
{% endhighlight %}
build.sh中详细说明了各个参数的含义，-d是以Debug模式编译，-t是编译测试用例，-i是增量编译。
第一次编译时会下载很多依赖包，所以耗时会很久，我当时在服务器上编译了大概1个半小时才完成(如果CPU核数够多可以在build.sh后加-jn参数指定编译的线程，n默认是8)。等到编译成功后我想测试一下mindspore是否成功安装(**必须使用bash build.sh -e gpu编译，才能进行以下测试**)：
{% highlight python %}
import mindspore
print(mindspore.__version__)
{% endhighlight %}
会报错，提示找不到__version__。查阅[文档](https://gitee.com/mindspore/mindspore#%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E6%96%B9%E5%BC%8F%E5%AE%89%E8%A3%85)发现，官方不建议在devel编译后直接安装whl包，而是建议在mindspore runtime镜像中安装，所以编译脚本没有自动安装已编译好的whl包。
为了方便验证，我直接在devel安装whl(读者也可以自己拉取runtime镜像后安装):
{% highlight bash %}
pip install ./output/mindspore-1.2.0-cp37-cp37m-linux_x86_64.whl
{% endhighlight %}
然后再运行上面那条语句就可以成功输出mindspore的版本了。
### 编译脚本(可跳过)
MindSpore的项目很大，编译脚本非常复杂，但是我们后面要在VS Code中自定义Debug task来调用编译脚本，所以还是需要对编译脚本有一个总体认识，不想了解编译流程的同学可以直接跳过这部分进入下面的调试环节。总体流程是build.sh读取用户参数，设置cmake环境变量，然后调用cmake进行编译。如以下脚本片段：
{% highlight bash %}
# build.sh
build_mindspore()
{
    CMAKE_ARGS="-DDEBUG_MODE=$DEBUG_MODE -DBUILD_PATH=$BUILD_PATH -DX86_64_SIMD=${X86_64_SIMD}"
    if [[ "X$ENABLE_COVERAGE" = "Xon" ]]; then
      CMAKE_ARGS="${CMAKE_ARGS} -DENABLE_COVERAGE=ON"
    fi
    ...
    cmake --build . --target package ${CMAKE_VERBOSE} -j$THREAD_NUM
}
...
if [[ "X$COMPILE_LITE" = "Xon" ]]; then
  if [[ "X$LITE_LANGUAGE" = "Xjava" ]]; then
    build_java
  else
    build_lite
  fi
else
    build_mindspore
fi
{% endhighlight %}
可以从下面几行代码看出build.sh会根据不同的编译参数选择编译不同的代码模块(防止编译不必要的模块，以加快编译速度)，这些参数有默认值，也能被用户显示指定值。其中build_mindspore()模块负责编译MindSpore核心C++代码,可以看出它就是先设置cmake参数，最后再调用cmake命令进行编译。为了了解更多编译细节，我们需要查看CmakeLists.txt:
{% highlight cmake %}
# CMakeLists.txt
include(${CMAKE_SOURCE_DIR}/cmake/options.cmake)
include(${CMAKE_SOURCE_DIR}/cmake/check_requirements.cmake)
...
if(ENABLE_D OR ENABLE_ACL OR ENABLE_TESTCASES)
    include(${CMAKE_SOURCE_DIR}/cmake/dependency_graphengine.cmake)
endif()

add_subdirectory(mindspore/ccsrc)
add_subdirectory(mindspore/core)
if(ENABLE_TESTCASES OR ENABLE_CPP_ST)
    add_subdirectory(tests)
endif()
include(cmake/package.cmake)

# cmake/package.cmake
file(GLOB MS_PY_LIST ${CMAKE_SOURCE_DIR}/mindspore/*.py) # 定义变量MS_PY_LIST为/mindspore目录下的所有.py文件
install(
    FILES ${MS_PY_LIST}
    DESTINATION ${INSTALL_PY_DIR}
    COMPONENT mindspore
) # 将py文件都拷贝到安装目录
{% endhighlight %}
如上所示，除了include一些第三方库的编译文件外，CmakeLists.txt中主要指定了MindSpore自己需要编译的文件目录。options.cmake负责根据传入cmake的参数设置编译参数,check_requirements.cmake提供了一些检验编译依赖的函数, package.cmake负责将编译完成的动态链接库等文件安装到指定目录。由上面几行package.cmake中的命令可以看出，cmake直接将mindspore/目录下的所有python文件都拷贝到安装目录，没有类似C++的编译环节。

与build.sh一样，cmake也会通过不同的参数，决定编译哪些部分(如tests, graphengine等)。需要注意的是mindspore/ccsrc和mindspore/core，这两个目录下存放了MindSpore的核心C++代码，将它们include进来后，cmake会自动去这两个目录下寻找CmakeLists.txt文件并递归编译。ccsrc和core下的CmakeLists.txt文件就相对简单了，主要指定了编译的target及其依赖：
{% highlight cmake %}
# mindspore/core/CMakeLists.txt
file(GLOB_RECURSE CORE_SRC_LIST RELATIVE ${CMAKE_CURRENT_SOURCE_DIR}
  "abstract/*.cc"
  "base/*.cc"
  "ops/*.cc"
  "ir/*.cc"
  "utils/*.cc"
  "load_mindir/*.cc"
  ) # 定义变量CORE_SRC_LIST为几个子目录下的.cc文件
add_library(mindspore_core STATIC ${CORE_SRC_LIST}) # 定义新的编译生成库mindspore_core，由CORE_SRC_LIST编译生成
target_link_libraries(mindspore_core PRIVATE mindspore_gvar) # 给mindspore_core指定新的dependency库，mindspore_gvar
{% endhighlight %}
从上述CMakeLists.txt可以看出，我们如果在core/的子目录下添加.cc文件，无需修改编译脚本，但是如果想要添加新的子目录，就要将其加入file命令中。

其他各模块下的CmakeLists.txt也大同小异，如tests/, graphengine/等，感兴趣的同学可以自行探索。

## 调试C++代码
**必须调用bash build.sh -e gpu -d -t ut -i编译成功后，才能进行下面的调试。**
由于C++代码比较底层，测试的时候需要很多Context设置，所以我们直接调试测试用例，就不用自己编写测试代码了。我们发现tests/ut/runtest.sh接收cpp作为参数后，会调用tests/ut/cpp/runtest.sh:
{% highlight bash %}
# tests/ut/cpp/runtest.sh
export LD_LIBRARY_PATH=${BUILD_PATH}/mindspore/googletest/googlemock/gtest:${PROJECT_PATH}/mindspore:\
${PROJECT_PATH}/mindspore/lib:${PROJECT_PATH}/graphengine/third_party/prebuild/x86_64:\
${PROJECT_PATH}/graphengine/third_party/prebuild/aarch64:${LD_LIBRARY_PATH}
export PYTHONPATH=${PROJECT_PATH}/tests/ut/cpp/python_input:$PYTHONPATH:${PROJECT_PATH}
export GLOG_v=2
export GC_COLLECT_IN_CELL=1

cp -fr $PROJECT_PATH/tests/ut/data ${PROJECT_PATH}/build/mindspore/tests/ut/cpp/
python ${PROJECT_PATH}/build/mindspore/tests/ut/cpp/data/dataset/testAlbum/gen_json.py

if [ $# -gt 0 ]; then 
  ./ut_tests --gtest_filter=$1
else
  ./ut_tests
fi
{% endhighlight %}
上述脚本做了三件事：
1. 设置环境变量，包括指定动态库加载路径的LD_LIBRARY_PATH，指定python文件加载路径的PYTHONPATH
2. 拷贝一些必要的文件
3. 执行之前编译的二进制文件ut_tests

### gdb调试(可跳过)
gdb可以使用命令gdb ut_tests来轻松调试二进制代码，所以只要完成了上述脚本的步骤1、2，我们就能使用gdb调试ut_tests，从而进入到我们想要调试的C++文件中了。而1、2步骤，我们是可以通过命令完成的，首先要获取自己的PROJECT_PATH，即mindspore源码所在的绝对路径，然后执行:
{% highlight bash %}
vim ~/.bashrc
# 在最下面添加：
export PROJECT_PATH=/dev/mindspore/mindspore
export BUILD_PATH=/dev/mindspore/mindspore/build
export LD_LIBRARY_PATH=${BUILD_PATH}/mindspore/googletest/googlemock/gtest:${PROJECT_PATH}/mindspore:\
${PROJECT_PATH}/mindspore/lib:${PROJECT_PATH}/graphengine/third_party/prebuild/x86_64:\
${PROJECT_PATH}/graphengine/third_party/prebuild/aarch64:\
${BUILD_PATH}/package/lib:${LD_LIBRARY_PATH}
export PYTHONPATH=${PROJECT_PATH}/tests/ut/cpp/python_input:$PYTHONPATH:${PROJECT_PATH}
export GLOG_v=2
# 保存文件后退出
source ~/.bashrc
cp -fr $PROJECT_PATH/tests/ut/data ${PROJECT_PATH}/build/mindspore/tests/ut/cpp/
python ${PROJECT_PATH}/build/mindspore/tests/ut/cpp/data/dataset/testAlbum/gen_json.py
{% endhighlight %}
再执行：
{% highlight bash %}
cd build/mindspore/tests/ut/cpp
gdb ut_tests
{% endhighlight %}
就成功使用gdb调试C++的测试用例了，下面可以使用gdb的命令设置断点、执行程序、打印变量等。
### VS Code调试(重要)
gdb虽然能够满足我们的基本调试功能，但是用起来非常不直观，比如设置断点、查看变量等都要使用命令。因此我想要在VS Code中设置断点并调试，思路就是参考上述gdb调试的流程，将其配置成VS Code的调试任务。首先我们需要在.vscode文件夹下的launch.json中添加gdb debug任务，并且在tasks.json中添加build任务:
{% highlight json %}
// .vscode/launch.json
{
    "configurations": [
        {
            "name": "(gdb) Launch",
            "type": "cppdbg",
            "request": "launch",
            "program": "${workspaceFolder}/mindspore/build/mindspore/tests/ut/cpp/ut_tests",  //指定调试程序
            "args": [
                "--gtest_filter=TestPynativeExecute.TestCreateContext" //ut_tests使用了gtest框架，该参数可以指定特定测试用例执行
            ],
            "stopAtEntry": false,
            "cwd": "${workspaceFolder}/mindspore/build/mindspore/tests/ut/cpp",
            "externalConsole": false,
            "MIMode": "gdb",
            "setupCommands": [
                {
                    "description": "Enable pretty-printing for gdb",
                    "text": "-enable-pretty-printing",
                    "ignoreFailures": true
                }
            ],
            "envFile": "${workspaceFolder}/.vscode/project.env", //放置tests/ut/cpp/runtest.sh脚本中的环境变量
            "preLaunchTask": "build"
        }
    ]
}

// .vscode/tasks.json
{
    "version": "2.0.0",
    "tasks": [
        {
          "label": "build",
          "type": "shell",
          "command": "${workspaceFolder}/mindspore/build.sh",
          "args": [
           "-e", "gpu", "-d", "-t", "ut", "-j16", "-i"
          ],
          "options": {
              "cwd": "${workspaceFolder}/mindspore/",
          }
        }
    ]
  }
{% endhighlight %}
添加环境变量配置文件：
{% highlight bash %}
# .vscode/project.env
# 为了保证正确，这里我都写成了绝对路径，读者也可以尝试使用${PROJECT_PATH}等变量
PROJECT_PATH=/dev/mindspore/mindspore
BUILD_PATH=/dev/mindspore/mindspore/build
LD_LIBRARY_PATH=/dev/mindspore/mindspore/build/mindspore/googletest/googlemock/gtest:/dev/mindspore/mindspore/mindspore:/dev/mindspore/mindspore/mindspore/lib:/dev/mindspore/mindspore/graphengine/third_party/prebuild/x86_64:/dev/mindspore/mindspore/graphengine/third_party/prebuild/aarch64:/dev/mindspore/mindspore/build/package/lib
PYTHONPATH=/dev/mindspore/mindspore/tests/ut/cpp/python_input:/dev/mindspore/mindspore
GLOG_v=2
GC_COLLECT_IN_CELL=1
{% endhighlight %}

回顾下，我们在阅读test_transpose.py的实现时，最后追到了mindspore/ccsrc/pipeline/pynative/pynative_execute.cc中的RunOp方法，因此我希望找到pynative_execute的测试用例进行调试，就可能进入RunOp方法中了。找到了tests/ut/cpp/pynative/pynative_execute_test.cc，设置断点，选择gdb debug任务并点击执行(左上角)：
<div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="{{ site.baseurl }}/assets/img/ms/2/cppdebug1.png">
</div>
VS Code在执行launch.json中配置的debug任务前，会自动调用preLanuchTask进行编译，编译完成后执行debug任务，就能成功进入断点位置了：
<div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="{{ site.baseurl }}/assets/img/ms/2/cppdebug2.png">
</div>
这样我们也能查看C++代码的变量信息、调用栈了。我在RunOp函数中设置断点后，继续执行debug，却没有进入断点。经过分析，pynative_execute_test.cc似乎并没有真正地运行operation:

{% highlight cpp %}
# tests/ut/cpp/pynative/pynative_execute_test.cc
OpExecInfoPtr ConstructOpExecInfo() {
  ...
  return PynativeExecutor::GetInstance()->forward_executor()->GenerateOpExecInfo(args);
}

TEST_F(TestPynativeExecute, TestCreateContext) {
  auto ctx3 = MsContext::GetInstance();
  ASSERT_EQ(ctx3->backend_policy(), "vm");
  ASSERT_EQ(ctx3->get_param<std::string>(MS_CTX_DEVICE_TARGET), "CPU");

  ctx3->set_backend_policy("ge_only");
  ctx3->set_param<std::string>(MS_CTX_DEVICE_TARGET, "GPU");
  auto ctx4 = MsContext::GetInstance();

  ASSERT_EQ(ctx3.get(), ctx4.get());
  ASSERT_EQ(ctx4->backend_policy(), "ge_only");
  ASSERT_EQ(ctx4->get_param<std::string>(MS_CTX_DEVICE_TARGET), "GPU");
}

TEST_F(TestPynativeExecute, TestDefaultContext) {
  auto ctx = MsContext::GetInstance();
  ASSERT_EQ(std::string(ctx->backend_policy()), "ge_only");
  auto ctx2 = MsContext::GetInstance();
  ASSERT_EQ(ctx.get(), ctx2.get());
}
{% endhighlight %}
它里面只有这两个测试用例，似乎都是测试MsContext的，并非是PyNativeExecute。而且这个文件中还有一个未被调用的方法ConstructOpExecInfo，生成了一个PynativeExecutor Operator的调用信息。因此我大胆地猜测，这个测试用例还未写完，后面应该会补上使用PyNativeExecute执行算子的测试，这样才会调用RunOp方法，这点还有待跟MindSpore开发团队确认。

## 下期预告
接下来我们小组可能会从几个角度去继续进行源码的阅读评注：
- Python/C++测试用例的编写
- 自定义算子相关代码
- PyNative与Graph模式运行相关
- IR与基于源码转换的自动微分

### 部分参考：
- https://www.jianshu.com/p/c3806d2ad1f8
- https://code.visualstudio.com/docs/editor/tasks
- https://code.visualstudio.com/docs/cpp/launch-json-reference

## test
## 测试